{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install ftfy --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import ftfy\n","import re\n","import os\n","\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer \n","from transformers import pipeline\n","from transformers import DefaultDataCollator\n","from huggingface_hub import HfApi, HfFolder"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","\n","# Nonaktifkan semua warning\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["# Data Engineering"]},{"cell_type":"markdown","metadata":{},"source":["#### Read Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/big-data-challenge-2024/dataset_penyisihan_bdc_2024(in).csv',delimiter=';')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,12))\n","sns.countplot(data=train,x='label')"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Preparation"]},{"cell_type":"markdown","metadata":{},"source":["**Text Cleaning**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def bersihkan_data_duplikat(df, kolom_teks='text', kolom_label='label'):\n","    # Temukan teks yang duplikat\n","    duplikat = df[df[kolom_teks].duplicated(keep=False)]\n","\n","    # Hitung frekuensi label untuk setiap teks yang duplikat\n","    frekuensi_label = duplikat.groupby(kolom_teks)[kolom_label].value_counts().unstack(fill_value=0)\n","\n","    # Pilih label dengan frekuensi tertinggi untuk setiap teks yang duplikat\n","    label_terbanyak = frekuensi_label.idxmax(axis=1)\n","\n","    # Buat DataFrame baru dengan label terbanyak\n","    df_baru = df.drop_duplicates(subset=kolom_teks, keep=False)\n","    df_baru = df_baru.set_index(kolom_teks)\n","    df_baru[kolom_label] = label_terbanyak\n","    df_baru = df_baru.reset_index()\n","\n","    # Gabungkan DataFrame baru dengan baris yang tidak duplikat\n","    df_final = pd.concat([df_baru, df[~df[kolom_teks].isin(duplikat[kolom_teks])]]).sort_index()\n","\n","    return df_final[~df_final[kolom_label].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Buang duplikat pada data train\n","train = bersihkan_data_duplikat(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def clean_tweet(tweet):\n","    # Memperbaiki teks yang terdistorsi akibat kesalahan encoding\n","    tweet = ftfy.fix_text(tweet)\n","    # Hapus karakter newline\n","    tweet = tweet.replace('\\n', ' ')\n","    # Hapus spasi berlebih yang mungkin tersisa\n","    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n","    # Lowercasting\n","    tweet = tweet.lower()\n","   \n","    return tweet.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Bersihkan setiap tweet pada dataset\n","train['cleaned_text'] = train['text'].apply(clean_tweet)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Drop baris dengan string kosong\n","drop_index = train[train['cleaned_text'].str.len() == 0].index\n","train = train.drop(drop_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Drop un-processed text column\n","train = train.drop(columns=['text'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Prepare Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_mapping = {label: idx for idx, label in enumerate(train['label'].unique())}\n","train['label'] = train['label'].map(label_mapping)\n","\n","print(label_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_texts, val_texts, train_labels, val_labels = train_test_split(train['cleaned_text'], train['label'], test_size=0.2, random_state=42,stratify=train['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define model tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ChunkTextDataset(torch.utils.data.Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=512):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.windows = []\n","        self.labels = []\n","\n","        self._create_windows(texts, labels)\n","\n","    def _create_windows(self, texts, labels):\n","        for text, label in zip(texts, labels):\n","            tokens = self.tokenizer(text, truncation=False)\n","            input_ids = tokens['input_ids']\n","           \n","            if len(input_ids) < self.max_length:\n","                window = input_ids + [self.tokenizer.pad_token_id] * (self.max_length - len(input_ids))\n","                self.windows.append(window)\n","                self.labels.append(label)\n","            else:\n","                input_ids = input_ids[1:-1]\n","                start = 0\n","                while start < len(input_ids):\n","                    end = start + (self.max_length - 2)\n","                    window = [self.tokenizer.cls_token_id] + input_ids[start:end] + [self.tokenizer.sep_token_id]\n","                    if len(window) < self.max_length:\n","                        window = window + [self.tokenizer.pad_token_id] * (self.max_length - len(window))\n","                    self.windows.append(window)\n","                    self.labels.append(label)\n","                    start += self.max_length - 2\n","\n","    def __len__(self):\n","        return len(self.windows)\n","\n","    def __getitem__(self, idx):\n","        item = {'input_ids': self.windows[idx]}\n","        attention_mask = [1 if token != self.tokenizer.pad_token_id else 0 for token in item['input_ids']]\n","        item['attention_mask'] = attention_mask\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return {key: torch.tensor(val) for key, val in item.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Buat dataset untuk pelatihan dan pengujian\n","train_dataset = ChunkTextDataset(train_texts, train_labels.tolist(), tokenizer)\n","val_dataset = ChunkTextDataset(val_texts, val_labels.tolist(), tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["# Modelling"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Simpan token API Hugging Face Anda di variabel lingkungan\n","os.environ['HF_TOKEN'] = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Login menggunakan token API\n","hf_api = HfApi()\n","HfFolder.save_token(os.environ['HF_TOKEN'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Verifikasi login\n","user_info = hf_api.whoami()\n","print(f\"Logged in as: {user_info['name']}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained('indolem/indobertweet-base-uncased', num_labels=len(label_mapping))\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    bal_acc = balanced_accuracy_score(labels, preds)\n","    return {\n","        'balanced_accuracy': bal_acc,\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='model/indonesia-election-topic-classification',\n","    num_train_epochs=7,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    push_to_hub=True,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"balanced_accuracy\",\n","    report_to = \"none\"\n",")\n","\n","data_collator = DefaultDataCollator()\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["#### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eval_results = trainer.evaluate()\n","print(eval_results)"]},{"cell_type":"markdown","metadata":{},"source":["#### Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.save_model(\"indonesia-election-topic-classification\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.push_to_hub()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5144973,"sourceId":8729021,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
